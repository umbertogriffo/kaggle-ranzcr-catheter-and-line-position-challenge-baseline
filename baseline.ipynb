{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "baseline",
      "provenance": [],
      "collapsed_sections": [
        "jTXksFtiHfDH",
        "pBETV6aO2d39",
        "oBEqkWIpH0zJ",
        "pRmp45qYY1NJ",
        "j3YbTNckY4ua"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umbertogriffo/kaggle-ranzcr-catheter-and-line-position-challenge-baseline/blob/master/baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTXksFtiHfDH"
      },
      "source": [
        "# Install Kaggle API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMvFLpBQlBTR",
        "outputId": "c87a0896-f697-4ea9-8331-001e0d8d3e8f"
      },
      "source": [
        "!pip install kaggle\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle # force install the latest version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/33/365c0d13f07a2a54744d027fe20b60dacdfdfb33bc04746db6ad0b79340b/kaggle-1.5.10.tar.gz (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.10-cp37-none-any.whl size=73269 sha256=84a7acdc75bb1eee0932dd91f7aee8b67b5b2f6d7ad21d66c48a36708b7fcb31\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/d1/7e/6ce09b72b770149802c653a02783821629146983ee5a360f10\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Found existing installation: kaggle 1.5.10\n",
            "    Uninstalling kaggle-1.5.10:\n",
            "      Successfully uninstalled kaggle-1.5.10\n",
            "Successfully installed kaggle-1.5.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBETV6aO2d39"
      },
      "source": [
        "# API Credentials\n",
        "\n",
        "To use the Kaggle API, sign up for a Kaggle account at https://www.kaggle.com. Then go to the 'Account' tab of your user profile (https://www.kaggle.com/username/account) and select 'Create API Token'. This will trigger the download of kaggle.json, a file containing your API credentials. \n",
        "\n",
        "Place this file on your Google Drive anywhere.\n",
        "\n",
        "With the next snippet you download your credentials to Colab and you can start using Kaggle API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCfsJyQs2uUo",
        "outputId": "5fe3b0ce-ce68-42dd-e3ac-32e2a6f37d52"
      },
      "source": [
        "# Install gcloud python module and google-api-python-client module\n",
        "!pip install --upgrade gcloud\n",
        "!pip install --upgrade google-api-python-client"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gcloud\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/ab/d0cee58db2d8445c26e6f5db25d9b1f1aa14a3ab30eea8ce77ae808d10ef/gcloud-0.18.3.tar.gz (454kB)\n",
            "\r\u001b[K     |▊                               | 10kB 13.7MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 12.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30kB 9.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 40kB 8.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 61kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 71kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 81kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 92kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 102kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 112kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 122kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 133kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 143kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 153kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 163kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 174kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 184kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 194kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 204kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 215kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 225kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 235kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 245kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 256kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 266kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 276kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 286kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 296kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 307kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 317kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 327kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 337kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 348kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 358kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 368kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 378kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 389kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 399kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 409kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 419kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 430kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 440kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 450kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 460kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from gcloud) (0.17.4)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos in /usr/local/lib/python3.7/dist-packages (from gcloud) (1.53.0)\n",
            "Requirement already satisfied, skipping upgrade: oauth2client>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from gcloud) (4.1.3)\n",
            "Requirement already satisfied, skipping upgrade: protobuf!=3.0.0.b2.post1,>=3.0.0b2 in /usr/local/lib/python3.7/dist-packages (from gcloud) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from gcloud) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=2.0.1->gcloud) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=2.0.1->gcloud) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=2.0.1->gcloud) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.0.0.b2.post1,>=3.0.0b2->gcloud) (54.0.0)\n",
            "Building wheels for collected packages: gcloud\n",
            "  Building wheel for gcloud (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gcloud: filename=gcloud-0.18.3-cp37-none-any.whl size=602938 sha256=d65228da4db169ea1ea0d625a2a33a087c0e763950fc4fa5b8794d50bbf7b229\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/9b/9c/a01be401658fea33b93a35d03921b0c638266821b264dc8662\n",
            "Successfully built gcloud\n",
            "Installing collected packages: gcloud\n",
            "Successfully installed gcloud-0.18.3\n",
            "Collecting google-api-python-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/56/bc7314cd180d1420e4ef11202dc9548ec22237a0a6de1aaf37b460ee7753/google_api_python_client-2.0.2-py2.py3-none-any.whl (6.5MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (3.0.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (1.27.1)\n",
            "Requirement already satisfied, skipping upgrade: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (0.0.4)\n",
            "Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client) (0.17.4)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (1.53.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (54.0.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2dev,>=1.16.0->google-api-python-client) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2dev,>=1.16.0->google-api-python-client) (4.2.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2dev,>=1.16.0->google-api-python-client) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2dev,>=1.16.0->google-api-python-client) (0.4.8)\n",
            "Installing collected packages: google-api-python-client\n",
            "  Found existing installation: google-api-python-client 1.12.8\n",
            "    Uninstalling google-api-python-client-1.12.8:\n",
            "      Successfully uninstalled google-api-python-client-1.12.8\n",
            "Successfully installed google-api-python-client-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5_288BYp6H1",
        "outputId": "ac09ba4d-3097-4528-eb76-a077f05cfbe9"
      },
      "source": [
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Download 100%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYlMHoUHGaCx"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBEqkWIpH0zJ"
      },
      "source": [
        "# Download The Dataset From Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDyKzZPtOV1-",
        "outputId": "97302ff5-2584-4e91-cdc4-aebec3be9c6e"
      },
      "source": [
        "!kaggle competitions download -c ranzcr-clip-catheter-line-classification -p /content/\n",
        "!unzip -q /content/ranzcr-clip-catheter-line-classification.zip\n",
        "!rm /content/ranzcr-clip-catheter-line-classification.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading ranzcr-clip-catheter-line-classification.zip to /content\n",
            "100% 11.7G/11.7G [03:12<00:00, 69.6MB/s]\n",
            "100% 11.7G/11.7G [03:12<00:00, 65.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyOzEerhOqsJ",
        "outputId": "ea205b5c-d008-4953-dc3a-191726362fa2"
      },
      "source": [
        "%cd /content\n",
        "!ls"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "adc.json\t       test\t       train_annotations.csv\n",
            "sample_data\t       test_tfrecords  train.csv\n",
            "sample_submission.csv  train\t       train_tfrecords\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oggOAd7N_u_n"
      },
      "source": [
        "# Enabling and testing the TPU\r\n",
        "\r\n",
        "First, you'll need to enable TPUs for the notebook:\r\n",
        "\r\n",
        "- Navigate to Edit→Notebook Settings\r\n",
        "- select TPU from the Hardware Accelerator drop-down\r\n",
        "\r\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azlOYigdAHQW",
        "outputId": "0d10b552-e6aa-4f51-9030-70db918740a5"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "print(\"Tensorflow version \" + tf.__version__)\r\n",
        "import os\r\n",
        "\r\n",
        "def auto_select_accelerator(tpu_worker_address=None):\r\n",
        "    try:\r\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_worker_address) # TPU detection\r\n",
        "        tf.config.experimental_connect_to_cluster(tpu)\r\n",
        "        tf.tpu.experimental.initialize_tpu_system(tpu)\r\n",
        "        strategy = tf.distribute.TPUStrategy(tpu)\r\n",
        "        print(\"Running on TPU:\", tpu.master())\r\n",
        "    except ValueError:\r\n",
        "        print('Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\r\n",
        "        strategy = tf.distribute.get_strategy()\r\n",
        "    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\r\n",
        "    \r\n",
        "    return strategy\r\n",
        "\r\n",
        "strategy = auto_select_accelerator()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.1\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.119.180.18:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.119.180.18:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on TPU: grpc://10.119.180.18:8470\n",
            "Running on 8 replicas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub_StX_SAHne",
        "outputId": "56a079b7-d38a-4ed9-993b-1cc7eea08445"
      },
      "source": [
        "# Listing Devices\r\n",
        "from tensorflow.python.client import device_lib\r\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 16945333004305610030]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8MgQBwwiAMWT",
        "outputId": "ce3443f3-71c5-4a34-dafd-0a151f443973"
      },
      "source": [
        "# Testing for GPU\r\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRmp45qYY1NJ"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Gj7cC2as8-6",
        "outputId": "1d164d81-d9a2-4317-e4a4-78e7263e1030"
      },
      "source": [
        "# http://scikit.ml/stratification.html\r\n",
        "# http://scikit.ml/api/skmultilearn.model_selection.iterative_stratification.html#skmultilearn.model_selection.iterative_stratification.iterative_train_test_split\r\n",
        "!pip install scikit-multilearn\r\n",
        "!pip install arff\r\n",
        "# https://www.tensorflow.org/addons\r\n",
        "!pip install tensorflow-addons"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-multilearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/1f/e6ff649c72a1cdf2c7a1d31eb21705110ce1c5d3e7e26b2cc300e1637272/scikit_multilearn-0.2.0-py3-none-any.whl (89kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 10.4MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 40kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 51kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 61kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 71kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 81kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 4.3MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n",
            "Collecting arff\n",
            "  Downloading https://files.pythonhosted.org/packages/50/de/62d4446c5a6e459052c2f2d9490c370ddb6abc0766547b4cef585913598d/arff-0.9.tar.gz\n",
            "Building wheels for collected packages: arff\n",
            "  Building wheel for arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for arff: filename=arff-0.9-cp37-none-any.whl size=4970 sha256=e73ad94ade5bc71a0776ed044d654fe27f2bd19ac1cbdc045ca74be1dfeb5239\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/d0/70/2c73afedd3ac25c6085b528742c69b9587cbdfa67e5194583b\n",
            "Successfully built arff\n",
            "Installing collected packages: arff\n",
            "Successfully installed arff-0.9\n",
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "\u001b[K     |████████████████████████████████| 706kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.12.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufm6-06eCxnA"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import gc\n",
        "import os\n",
        "from glob import glob\n",
        "from random import shuffle\n",
        "import cv2\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from albumentations import Compose, RandomRotate90, Transpose, Flip, OneOf, CLAHE, IAASharpen, IAAEmboss, RandomBrightnessContrast, JpegCompression, Blur, GaussNoise, HueSaturationValue, ShiftScaleRotate, Normalize\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from skmultilearn.model_selection import iterative_train_test_split, IterativeStratification\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications import NASNetLarge, InceptionResNetV2, Xception, EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7, ResNet152V2\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN, LearningRateScheduler\n",
        "from tensorflow.keras.layers import Lambda, Reshape, DepthwiseConv2D, ZeroPadding2D, Add, MaxPooling2D,Activation, Flatten, Conv2D, Dense, Input, Dropout, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg6uFuRPJBFX"
      },
      "source": [
        "For reproducibility:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb5A1QoejOVy"
      },
      "source": [
        "SEED = 42\r\n",
        "\r\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "tf.random.set_seed(SEED)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3YbTNckY4ua"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FARFLMY4ISqM"
      },
      "source": [
        "## Build Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_7AdBHLCa8k"
      },
      "source": [
        "def build_decoder(target_size, with_labels=True, ext='jpg'):\r\n",
        "    def decode(path):\r\n",
        "        file_bytes = tf.io.read_file(path) # Reads and outputs the entire contents of the input filename.\r\n",
        "\r\n",
        "        if ext == 'png':\r\n",
        "            img = tf.image.decode_png(file_bytes, channels=3) # Decode a PNG-encoded image to a uint8 or uint16 tensor\r\n",
        "        elif ext in ['jpg', 'jpeg']:\r\n",
        "            img = tf.image.decode_jpeg(file_bytes, channels=3) # Decode a JPEG-encoded image to a uint8 tensor\r\n",
        "        else:\r\n",
        "            raise ValueError(\"Image extension not supported\")\r\n",
        "\r\n",
        "        img = tf.cast(img, tf.float32) / 255.0 # Casts a tensor to the type float32 and divides by 255.\r\n",
        "        img = tf.image.resize(img, target_size) # Resizing to target size\r\n",
        "        return img\r\n",
        "    \r\n",
        "    def decode_with_labels(path, label):\r\n",
        "        return decode(path), tf.dtypes.cast(label, tf.float32)\r\n",
        "    \r\n",
        "    return decode_with_labels if with_labels else decode\r\n",
        "\r\n",
        "def build_augmenter(with_labels=True):\r\n",
        "  \"\"\"\r\n",
        "  When you don't have a large image dataset, it's a good practice \r\n",
        "  to artificially introduce sample diversity by applying random, yet realistic,\r\n",
        "  transformations to the training images, such as rotation and \r\n",
        "  horizontal flipping. This helps expose the model to different aspects \r\n",
        "  of the training data and reduce overfitting.\r\n",
        "  \"\"\"\r\n",
        "  def augment(img):\r\n",
        "      img = tf.image.random_flip_left_right(img)\r\n",
        "      img = tf.image.random_flip_up_down(img)\r\n",
        "      img = tf.image.random_saturation(img, 0.8, 1.2)\r\n",
        "      img = tf.image.random_brightness(img, 0.2)\r\n",
        "      img = tf.image.random_contrast(img, 0.8, 1.2)\r\n",
        "      img = tf.image.random_hue(img, 0.2)\r\n",
        "      return img\r\n",
        "  \r\n",
        "  def augment_with_labels(img, label):\r\n",
        "      return augment(img), label\r\n",
        "  \r\n",
        "  return augment_with_labels if with_labels else augment\r\n",
        "\r\n",
        "def build_dataset(paths, labels=None, bsize=32, cache=True,\r\n",
        "                  decode_fn=None, augment_fn=None,\r\n",
        "                  augment=True, repeat=True, shuffle=1024, \r\n",
        "                  cache_dir=\"\"):\r\n",
        "    if cache_dir != \"\" and cache is True:\r\n",
        "        os.makedirs(cache_dir, exist_ok=True)\r\n",
        "    \r\n",
        "    if decode_fn is None:\r\n",
        "        decode_fn = build_decoder(labels is not None)\r\n",
        "    \r\n",
        "    if augment_fn is None:\r\n",
        "        augment_fn = build_augmenter(labels is not None)\r\n",
        "    \r\n",
        "    AUTO = tf.data.experimental.AUTOTUNE\r\n",
        "    slices = paths if labels is None else (paths, labels)\r\n",
        "    # Better performance with the tf.data API\r\n",
        "    # https://www.tensorflow.org/guide/data_performance\r\n",
        "    dset = tf.data.Dataset.from_tensor_slices(slices)\r\n",
        "    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\r\n",
        "    dset = dset.cache(cache_dir) if cache else dset\r\n",
        "    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\r\n",
        "    dset = dset.repeat() if repeat else dset\r\n",
        "    dset = dset.shuffle(shuffle) if shuffle else dset\r\n",
        "    # Use buffered prefetching to load images from disk without having I/O become blocking.\r\n",
        "    dset = dset.batch(bsize).prefetch(AUTO)\r\n",
        "    return dset\r\n",
        "\r\n",
        "def build_tta(paths, bsize=32, decode_fn = None, augment_fn = None, tta = False):\r\n",
        "  \r\n",
        "  AUTO = tf.data.experimental.AUTOTUNE\r\n",
        "  dset = tf.data.Dataset.from_tensor_slices(paths)\r\n",
        "  dset = dset.map(decode_fn, num_parallel_calls = AUTO)\r\n",
        "  dset = dset.map(augment_fn, num_parallel_calls = AUTO)\r\n",
        "  if tta:\r\n",
        "    dset = dset.repeat() \r\n",
        "  dset = dset.batch(bsize)\r\n",
        "  # Use buffered prefetching to load images from disk without having I/O become blocking.\r\n",
        "  dset = dset.prefetch(AUTO)\r\n",
        "  return dset"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPENwlyLJN-J"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQRpVRq4JNfx"
      },
      "source": [
        "def get_model(architecture, img_size, n_classes):\r\n",
        "  # At the time of writing, Keras ships with ten of these pre-trained models \r\n",
        "  # already built into the library:\r\n",
        "  # https://keras.io/api/applications/\r\n",
        "  if architecture == \"Xception\":\r\n",
        "    net = Xception(include_top=False,input_shape=(img_size, img_size, 3), weights='imagenet')\r\n",
        "  elif architecture == \"ResNet152V2\":\r\n",
        "    net = ResNet152V2(include_top=False,input_shape=(img_size, img_size, 3), weights='imagenet')\r\n",
        "  elif architecture == \"NASNetLarge\":\r\n",
        "    net = NASNetLarge(include_top=False,input_shape=(img_size, img_size, 3), weights='imagenet')\r\n",
        "  elif architecture == \"InceptionResNetV2\":\r\n",
        "    net = InceptionResNetV2(include_top=False,input_shape=(img_size, img_size, 3), weights='imagenet')\r\n",
        "  elif architecture == \"EfficientNetB0\":\r\n",
        "    net = EfficientNetB0(include_top=False,input_shape=(img_size, img_size, 3), weights='imagenet')\r\n",
        "  elif architecture == \"EfficientNetB1\":\r\n",
        "    net = EfficientNetB1(include_top=False,input_shape=(img_size, img_size, 3), weights='imagenet')\r\n",
        "  elif architecture == \"EfficientNetB2\":\r\n",
        "    net = EfficientNetB2(include_top=False,input_shape=(img_size, img_size, 3), weights='imagenet')\r\n",
        "  elif architecture == \"EfficientNetB3\":\r\n",
        "    net = EfficientNetB3(include_top=False,input_shape=(img_size, img_size, 3), weights='imagenet')\r\n",
        "  elif architecture == \"EfficientNetB4\":\r\n",
        "    net = EfficientNetB4(include_top=False,input_shape=(img_size, img_size, 3), weights='imagenet')\r\n",
        "  elif architecture == \"EfficientNetB5\":\r\n",
        "    net = EfficientNetB5(include_top=False,input_shape=(img_size, img_size, 3), weights='imagenet')\r\n",
        "  elif architecture == \"EfficientNetB6\":\r\n",
        "    net = EfficientNetB6(include_top=False,input_shape=(img_size, img_size, 3), weights='imagenet')\r\n",
        "  elif architecture == \"EfficientNetB7\":\r\n",
        "    net = EfficientNetB7(include_top=False,input_shape=(img_size, img_size, 3), weights='imagenet')\r\n",
        "  else:\r\n",
        "     raise BaseException(f\"The architecture {architecture} is not supported.\")\r\n",
        "  x = net.output\r\n",
        "  x = GlobalAveragePooling2D()(x)\r\n",
        "  output = Dense(n_classes, activation='sigmoid')(x)\r\n",
        "  model = Model(inputs=net.input, outputs=output)\r\n",
        "\r\n",
        "  return model\r\n",
        "\r\n",
        "def compile_model(strategy, architecture, img_size, n_classes):\r\n",
        "  with strategy.scope():\r\n",
        "    model = get_model(architecture, img_size, n_classes)\r\n",
        "    model.compile(tf.optimizers.Adam(lr=1e-3),\r\n",
        "                  loss=tfa.losses.SigmoidFocalCrossEntropy(alpha = 0.50, gamma = 2.0),\r\n",
        "                  metrics=[tf.keras.metrics.AUC(name=\"auc\", multi_label=True)])\r\n",
        "    return model\r\n",
        "\r\n",
        "def get_callbacks(model_path, lrfn=None):\r\n",
        "\r\n",
        "  callbacks = []\r\n",
        "\r\n",
        "  callbacks.append(TerminateOnNaN())\r\n",
        "\r\n",
        "  callbacks.append(EarlyStopping(\r\n",
        "        monitor='val_loss',\r\n",
        "        patience=5,\r\n",
        "        mode='min',\r\n",
        "        verbose=1,\r\n",
        "        restore_best_weights=True))\r\n",
        "\r\n",
        "  callbacks.append(ModelCheckpoint(\r\n",
        "        model_path,\r\n",
        "        monitor='val_loss',\r\n",
        "        verbose=1,\r\n",
        "        save_best_only=True,\r\n",
        "        mode='min'))\r\n",
        "\r\n",
        "  callbacks.append(ReduceLROnPlateau(\r\n",
        "        monitor='val_loss', \r\n",
        "        factor=0.8, \r\n",
        "        patience=2, \r\n",
        "        verbose=1, \r\n",
        "        mode='auto', \r\n",
        "        min_delta=0.0001, \r\n",
        "        cooldown=5, \r\n",
        "        min_lr=0.00001))\r\n",
        "  \r\n",
        "  if lrfn is not None:\r\n",
        "    callbacks.append(lrfn)\r\n",
        "\r\n",
        "  return callbacks"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljg7Ba5Oahdn"
      },
      "source": [
        "## LR Finder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oez6tUb1ah1W"
      },
      "source": [
        "class LRFinder(Callback):\r\n",
        "    \"\"\"\r\n",
        "    A simple callback for finding the optimal learning rate range for your model + dataset.\r\n",
        "\r\n",
        "    # Usage\r\n",
        "        ```python\r\n",
        "            lr_finder = LRFinder(min_lr=1e-5,\r\n",
        "                                 max_lr=1e-2,\r\n",
        "                                 steps_per_epoch=np.ceil(epoch_size/batch_size),\r\n",
        "                                 epochs=3)\r\n",
        "            model.fit(X_train, Y_train, callbacks=[lr_finder])\r\n",
        "\r\n",
        "            lr_finder.plot_loss()\r\n",
        "        ```\r\n",
        "\r\n",
        "    # Arguments\r\n",
        "        min_lr: The lower bound of the learning rate range for the experiment.\r\n",
        "        max_lr: The upper bound of the learning rate range for the experiment.\r\n",
        "        steps_per_epoch: Number of mini-batches in the dataset. Calculated as `np.ceil(epoch_size/batch_size)`.\r\n",
        "        epochs: Number of epochs to run experiment. Usually between 2 and 4 epochs is sufficient.\r\n",
        "\r\n",
        "    # References\r\n",
        "        Blog post: jeremyjordan.me/nn-learning-rate\r\n",
        "        Original paper: https://arxiv.org/abs/1506.01186\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, min_lr=1e-5, max_lr=1e-2, steps_per_epoch=None, epochs=None):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.min_lr = min_lr\r\n",
        "        self.max_lr = max_lr\r\n",
        "        self.total_iterations = steps_per_epoch * epochs\r\n",
        "        self.iteration = 0\r\n",
        "        self.history = {}\r\n",
        "\r\n",
        "    def clr(self):\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        Calculate the learning rate.\r\n",
        "\r\n",
        "        :return:\r\n",
        "\r\n",
        "        \"\"\"\r\n",
        "        x = self.iteration / self.total_iterations\r\n",
        "        return self.min_lr + (self.max_lr - self.min_lr) * x\r\n",
        "\r\n",
        "    def on_train_begin(self, logs=None):\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        :param logs:\r\n",
        "        :return:\r\n",
        "        \"\"\"\r\n",
        "        '''Initialize the learning rate to the minimum value at the start of training.'''\r\n",
        "        logs = logs or {}\r\n",
        "        K.set_value(self.model.optimizer.lr, self.min_lr)\r\n",
        "\r\n",
        "    def on_batch_end(self, epoch, logs=None):\r\n",
        "        \"\"\"\r\n",
        "        Record previous batch statistics and update the learning rate.\r\n",
        "        :param epoch:\r\n",
        "        :param logs:\r\n",
        "        :return:\r\n",
        "        \"\"\"\r\n",
        "        logs = logs or {}\r\n",
        "        self.iteration += 1\r\n",
        "\r\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\r\n",
        "        self.history.setdefault('iterations', []).append(self.iteration)\r\n",
        "\r\n",
        "        for k, v in logs.items():\r\n",
        "            self.history.setdefault(k, []).append(v)\r\n",
        "\r\n",
        "        K.set_value(self.model.optimizer.lr, self.clr())\r\n",
        "\r\n",
        "    def plot_lr(self, results_dir=\"\"):\r\n",
        "        \"\"\"\r\n",
        "        Helper function to quickly inspect the learning rate schedule.\r\n",
        "        :return:\r\n",
        "        \"\"\"\r\n",
        "        fig_acc = plt.figure(figsize=(10, 10))\r\n",
        "        plt.plot(self.history['iterations'], self.history['lr'])\r\n",
        "        plt.yscale('log')\r\n",
        "        plt.xlabel('Iteration')\r\n",
        "        plt.ylabel('Learning rate')\r\n",
        "        plt.show()\r\n",
        "        fig_acc.savefig(results_dir + \"/model_lr.png\")\r\n",
        "\r\n",
        "        plt.cla()\r\n",
        "        plt.close()\r\n",
        "\r\n",
        "    def plot_loss(self, results_dir=\"\"):\r\n",
        "        \"\"\"\r\n",
        "        Helper function to quickly observe the learning rate experiment results\r\n",
        "        :return:\r\n",
        "        \"\"\"\r\n",
        "        fig_acc = plt.figure(figsize=(10, 10))\r\n",
        "        plt.plot(self.history['lr'], self.history['loss'])\r\n",
        "        plt.xscale('log')\r\n",
        "        plt.xlabel('Learning rate')\r\n",
        "        plt.ylabel('Loss')\r\n",
        "        plt.show()\r\n",
        "        fig_acc.savefig(results_dir + \"/model_lr_loss.png\")\r\n",
        "\r\n",
        "        plt.cla()\r\n",
        "        plt.close()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lAo8pBlhHk1"
      },
      "source": [
        "## Cosine annealing learning rate scheduler with periodic restarts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGUAv8d8hH80"
      },
      "source": [
        "class SGDRScheduler(Callback):\r\n",
        "    \"\"\"\r\n",
        "    Cosine annealing learning rate scheduler with periodic restarts.\r\n",
        "    # Usage\r\n",
        "        ```python\r\n",
        "            schedule = SGDRScheduler(min_lr=1e-5,\r\n",
        "                                     max_lr=1e-2,\r\n",
        "                                     steps_per_epoch=np.ceil(epoch_size/batch_size),\r\n",
        "                                     lr_decay=0.9,\r\n",
        "                                     cycle_length=5,\r\n",
        "                                     mult_factor=1.5)\r\n",
        "            model.fit(X_train, Y_train, epochs=100, callbacks=[schedule])\r\n",
        "        ```\r\n",
        "    # Arguments\r\n",
        "        min_lr: The lower bound of the learning rate range for the experiment.\r\n",
        "        max_lr: The upper bound of the learning rate range for the experiment.\r\n",
        "        steps_per_epoch: Number of mini-batches in the dataset. Calculated as `np.ceil(epoch_size/batch_size)`.\r\n",
        "        lr_decay: Reduce the max_lr after the completion of each cycle.\r\n",
        "                  Ex. To reduce the max_lr by 20% after each cycle, set this value to 0.8.\r\n",
        "        cycle_length: Initial number of epochs in a cycle.\r\n",
        "        mult_factor: Scale epochs_to_restart after each full cycle completion.\r\n",
        "    # References\r\n",
        "        Blog post: jeremyjordan.me/nn-learning-rate\r\n",
        "        Original paper: http://arxiv.org/abs/1608.03983\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self,\r\n",
        "                 min_lr,\r\n",
        "                 max_lr,\r\n",
        "                 steps_per_epoch,\r\n",
        "                 lr_decay=1,\r\n",
        "                 cycle_length=10,\r\n",
        "                 mult_factor=2):\r\n",
        "\r\n",
        "        self.min_lr = min_lr\r\n",
        "        self.max_lr = max_lr\r\n",
        "        self.lr_decay = lr_decay\r\n",
        "\r\n",
        "        self.batch_since_restart = 0\r\n",
        "        self.next_restart = cycle_length\r\n",
        "\r\n",
        "        self.steps_per_epoch = steps_per_epoch\r\n",
        "\r\n",
        "        self.cycle_length = cycle_length\r\n",
        "        self.mult_factor = mult_factor\r\n",
        "\r\n",
        "        self.best_weights = None\r\n",
        "\r\n",
        "        self.history = {}\r\n",
        "\r\n",
        "    def clr(self):\r\n",
        "        \"\"\"Calculate the learning rate.\"\"\"\r\n",
        "        fraction_to_restart = self.batch_since_restart / (self.steps_per_epoch * self.cycle_length)\r\n",
        "        lr = self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + np.cos(fraction_to_restart * np.pi))\r\n",
        "        return lr\r\n",
        "\r\n",
        "    def on_train_begin(self, logs={}):\r\n",
        "        \"\"\"Initialize the learning rate to the minimum value at the start of training.\"\"\"\r\n",
        "        logs = logs or {}\r\n",
        "        K.set_value(self.model.optimizer.lr, self.max_lr)\r\n",
        "\r\n",
        "    def on_batch_end(self, batch, logs={}):\r\n",
        "        \"\"\"Record previous batch statistics and update the learning rate.\"\"\"\r\n",
        "        logs = logs or {}\r\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\r\n",
        "        for k, v in logs.items():\r\n",
        "            self.history.setdefault(k, []).append(v)\r\n",
        "\r\n",
        "        self.batch_since_restart += 1\r\n",
        "        K.set_value(self.model.optimizer.lr, self.clr())\r\n",
        "\r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        \"\"\"Check for end of current cycle, apply restarts when necessary.\"\"\"\r\n",
        "        if epoch + 1 == self.next_restart:\r\n",
        "            self.batch_since_restart = 0\r\n",
        "            self.cycle_length = np.ceil(self.cycle_length * self.mult_factor)\r\n",
        "            self.next_restart += self.cycle_length\r\n",
        "            self.max_lr *= self.lr_decay\r\n",
        "            self.best_weights = self.model.get_weights()\r\n",
        "\r\n",
        "    def on_train_end(self, logs={}):\r\n",
        "        \"\"\"Set weights to the values from the end of the most recent cycle for best performance.\"\"\"\r\n",
        "        self.model.set_weights(self.best_weights)\r\n",
        "\r\n",
        "    def plot_lr(self, results_dir):\r\n",
        "        \"\"\"\r\n",
        "        Helper function to quickly observe the learning rate.\r\n",
        "        :return:\r\n",
        "        \"\"\"\r\n",
        "        fig_acc = plt.figure(figsize=(10, 10))\r\n",
        "        plt.plot(self.history['lr'])\r\n",
        "        plt.xlabel('Training Iteration')\r\n",
        "        plt.ylabel('Learning rate')\r\n",
        "        plt.show()\r\n",
        "        fig_acc.savefig(results_dir + \"/model_cyclic_lr.png\")\r\n",
        "\r\n",
        "        plt.cla()\r\n",
        "        plt.close()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtfnwYH8YlrY"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX7z2YdAHAX7"
      },
      "source": [
        "def plot_metric(history_in, metric_name, results_dir):\n",
        "    \"\"\"\n",
        "    Plot a metric of model's history.\n",
        "    \"\"\"\n",
        "\n",
        "    fig_acc = plt.figure(figsize=(10, 10))\n",
        "    plt.plot(history_in.history[metric_name])\n",
        "    plt.plot(history_in.history['val_' + metric_name])\n",
        "\n",
        "    plt.title('model ' + metric_name)\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    fig_acc.savefig(os.path.join(results_dir, \"model_\" + metric_name + \".png\"))\n",
        "\n",
        "    plt.cla()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def mkdir_if_not_exist(directory):\n",
        "\n",
        "        if not os.path.exists(directory):\n",
        "            try:\n",
        "                os.makedirs(directory)\n",
        "            except OSError as e:\n",
        "                print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QByTJjiEFGY"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Igr2qySaFEAm"
      },
      "source": [
        "# Cloud TPUs can only access data in GCS as only the GCS file system is registered.\r\n",
        "# https://stackoverflow.com/questions/62870656/file-system-scheme-local-not-implemented-in-google-colab-tpu\r\n",
        "# Colab can't use KaggleDatasets library, so we need to save the GCS path by ourself\r\n",
        "# copying it from a Kaggle notebook.\r\n",
        "GCS_DS_PATH = \"gs://kds-8e853601547c2d2e7a243638123e66bb32174c3a2b50da35aca5baed\""
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7fApdJ2EKxE",
        "outputId": "aae2818a-a3ff-41ba-9d0b-e5b3fc390d8d"
      },
      "source": [
        "df = pd.read_csv(\"/content/train.csv\")\n",
        "print(f\"{df.columns}\")\n",
        "print(len(df), df['StudyInstanceUID'].nunique())\n",
        "print('Number of Records:',len(df), 'Number of Patients:' ,df['PatientID'].nunique())"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['StudyInstanceUID', 'ETT - Abnormal', 'ETT - Borderline',\n",
            "       'ETT - Normal', 'NGT - Abnormal', 'NGT - Borderline',\n",
            "       'NGT - Incompletely Imaged', 'NGT - Normal', 'CVC - Abnormal',\n",
            "       'CVC - Borderline', 'CVC - Normal', 'Swan Ganz Catheter Present',\n",
            "       'PatientID'],\n",
            "      dtype='object')\n",
            "30083 30083\n",
            "Number of Records: 30083 Number of Patients: 3255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Bi_Gsp7CERSt",
        "outputId": "40325354-8e40-44fc-b407-1bff6aaeff3f"
      },
      "source": [
        "paths = GCS_DS_PATH + \"/train/\" + df['StudyInstanceUID'] + '.jpg'\r\n",
        "paths[0]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'gs://kds-8e853601547c2d2e7a243638123e66bb32174c3a2b50da35aca5baed/train/1.2.826.0.1.3680043.8.498.26697628953273228189375557799582420561.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMVxLnlpEPlP",
        "outputId": "d53d4a36-f5b5-4608-c004-a7aa34bd4ce9"
      },
      "source": [
        "# Get the multi-labels\n",
        "df_sub = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "labels_cols = df_sub.columns[1:]\n",
        "n_classes = len(labels_cols)\n",
        "print(f\"{n_classes} - {labels_cols}\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11 - Index(['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal', 'NGT - Abnormal',\n",
            "       'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal',\n",
            "       'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal',\n",
            "       'Swan Ganz Catheter Present'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqtTMHh2Gotv",
        "outputId": "931711c8-b998-413e-cd05-18f9c57441bd"
      },
      "source": [
        "labels = df[labels_cols].values\r\n",
        "labels"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 1, ..., 0, 1, 0],\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 1, ..., 0, 1, 0],\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 1, ..., 0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlheqgW_EjAu"
      },
      "source": [
        "id_label_map = {k: v for k, v in zip(paths, labels)}"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWU8HV5SLkmp",
        "cellView": "form"
      },
      "source": [
        "#@title Configuration\r\n",
        "#@markdown \r\n",
        "train_limit = 30083  #@param {type: \"number\"}\r\n",
        "test_limit = 3582  #@param {type: \"number\"}\r\n",
        "img_size =  512#@param {type:\"integer\"}\r\n",
        "batch_size_in =   16#@param {type: \"integer\", min: 8, max: 128}\r\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oyW2FInLYoN"
      },
      "source": [
        "## Build train and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq5l8ZAfK63v",
        "outputId": "d4aa0154-2b1b-40ae-e673-b12fe2eef659"
      },
      "source": [
        "ndarr_paths = np.reshape(paths.to_numpy(), (paths.shape[0], 1))\r\n",
        "ndarr_paths"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['gs://kds-8e853601547c2d2e7a243638123e66bb32174c3a2b50da35aca5baed/train/1.2.826.0.1.3680043.8.498.26697628953273228189375557799582420561.jpg'],\n",
              "       ['gs://kds-8e853601547c2d2e7a243638123e66bb32174c3a2b50da35aca5baed/train/1.2.826.0.1.3680043.8.498.46302891597398758759818628675365157729.jpg'],\n",
              "       ['gs://kds-8e853601547c2d2e7a243638123e66bb32174c3a2b50da35aca5baed/train/1.2.826.0.1.3680043.8.498.23819260719748494858948050424870692577.jpg'],\n",
              "       ...,\n",
              "       ['gs://kds-8e853601547c2d2e7a243638123e66bb32174c3a2b50da35aca5baed/train/1.2.826.0.1.3680043.8.498.43173270582850645437451931712017243531.jpg'],\n",
              "       ['gs://kds-8e853601547c2d2e7a243638123e66bb32174c3a2b50da35aca5baed/train/1.2.826.0.1.3680043.8.498.95092491950130838685690656747242898392.jpg'],\n",
              "       ['gs://kds-8e853601547c2d2e7a243638123e66bb32174c3a2b50da35aca5baed/train/1.2.826.0.1.3680043.8.498.99518162226171269731026325462883860316.jpg']],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By7tRC_ILYHD",
        "outputId": "dbd7d268-36a8-46d8-db72-029264a9fbe0"
      },
      "source": [
        "batch_size = strategy.num_replicas_in_sync * batch_size_in\r\n",
        "print(f\"Batch size: {batch_size}\")\r\n",
        "\r\n",
        "# train_paths, valid_paths, train_labels, valid_labels = train_test_split(paths[0:train_limit], labels[0:train_limit], test_size=0.1, shuffle=True, random_state=SEED)\r\n",
        "\r\n",
        "# Multi-label data stratification\r\n",
        "train_paths, train_labels, valid_paths, valid_labels = iterative_train_test_split(ndarr_paths[0:train_limit], labels[0:train_limit], test_size = 0.1)\r\n",
        "train_paths = train_paths.flatten()\r\n",
        "valid_paths = valid_paths.flatten()\r\n",
        "\r\n",
        "print(f\"# Training images: {train_paths.shape}\")\r\n",
        "print(f\"# Training labels: {train_labels.shape}\")\r\n",
        "print(f\"# Validation images: {valid_paths.shape}\")\r\n",
        "print(f\"# Validation labels: {valid_labels.shape}\")\r\n",
        "print(f\"# Training steps: {len(train_paths) // batch_size}\")\r\n",
        "print(f\"# Validation steps: {len(valid_paths) // batch_size}\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch size: 128\n",
            "# Training images: (27067,)\n",
            "# Training labels: (27067, 11)\n",
            "# Validation images: (3016,)\n",
            "# Validation labels: (3016, 11)\n",
            "# Training steps: 211\n",
            "# Validation steps: 23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spw89aX_LkKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aace6ef-f0cb-4dad-942d-e2bdba49b6d1"
      },
      "source": [
        "# Build the tensorflow datasets\r\n",
        "decoder = build_decoder(target_size=(img_size, img_size), with_labels=True)\r\n",
        "\r\n",
        "# Build the tensorflow datasets\r\n",
        "dtrain = build_dataset(\r\n",
        "    train_paths, train_labels, bsize=batch_size, decode_fn=decoder\r\n",
        ")\r\n",
        "\r\n",
        "dvalid = build_dataset(\r\n",
        "    valid_paths, valid_labels, bsize=batch_size, \r\n",
        "    repeat=False, shuffle=False, augment=False, decode_fn=decoder\r\n",
        ")\r\n",
        "\r\n",
        "dtrain"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, 512, 512, 3), (None, 11)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ6zYP7PY9lV"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1b-EM9fm4tg",
        "cellView": "form"
      },
      "source": [
        "#@title Configuration\n",
        "#@markdown \n",
        "output_path = \"model\" #@param {type: \"string\"}\n",
        "epochs = 30#@param {type:\"integer\"}\n",
        "n_fold = 5  #@param {type: \"slider\", min: 2, max: 10}\n",
        "architecture = \"Xception\" #@param [\"Xception\",\"InceptionResNetV2\",\"NASNetLarge\",\"ResNet152V2\", \"EfficientNetB0\", \"EfficientNetB1\", \"EfficientNetB2\", \"EfficientNetB3\", \"EfficientNetB4\", \"EfficientNetB5\", \"EfficientNetB6\", \"EfficientNetB7\"]\n",
        "use_lr_strategy = False #@param {type:\"boolean\"}\n",
        "use_lr_finder = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwp8FfHZ1L0T"
      },
      "source": [
        "### Single model\r\n",
        "To get maxmimum accuracy, we leverage a pretrained image recognition model. We drop the ImageNet-specific top layers (`include_top=false`), and add a max pooling and a softmax layer to predict our 11 classes.\r\n",
        "We also use [Focal loss](https://www.tensorflow.org/addons/api_docs/python/tfa/losses/SigmoidFocalCrossEntropy) since we have highly imbalanced classes. It down-weights well-classified examples and focuses on hard examples. The loss value is much high for a sample which is misclassified by the classifier as compared to the loss value corresponding to a well-classified example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5S6e2dIa4cT"
      },
      "source": [
        "#### Find the best learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "yDMlfc4ua42a",
        "outputId": "eea479f5-2032-473c-a0af-addb71b414c3"
      },
      "source": [
        "if use_lr_finder:\r\n",
        "  model = compile_model(strategy, architecture, img_size, n_classes)\r\n",
        "  lr_finder = LRFinder(min_lr=1e-5,\r\n",
        "                      max_lr=1e-2,\r\n",
        "                      steps_per_epoch=np.ceil(len(train_paths) // batch_size),\r\n",
        "                      epochs=3)\r\n",
        "  with strategy.scope():\r\n",
        "    model.fit(dtrain, \r\n",
        "              batch_size=batch_size, \r\n",
        "              callbacks=[lr_finder], \r\n",
        "              steps_per_epoch=len(train_paths) // batch_size)\r\n",
        "\r\n",
        "  lr_finder.plot_loss(\"\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  6/211 [..............................] - ETA: 1:46 - loss: 0.9202 - auc: 0.5001WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0041s vs `on_train_batch_end` time: 13.2419s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0041s vs `on_train_batch_end` time: 13.2419s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "211/211 [==============================] - 1023s 5s/step - loss: 0.3541 - auc: 0.7812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M2s1XzSliKh"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5D-lSKfP9JXG",
        "outputId": "1471dfb0-8c07-49f4-8644-d5f2bafcf713"
      },
      "source": [
        "path = os.path.join(\"output_path\", \"single_model\")\n",
        "mkdir_if_not_exist(path)\n",
        "model_path = os.path.join(path, f\"{architecture}_model.h5\")\n",
        "\n",
        "schedule = SGDRScheduler(min_lr=1e-3,\n",
        "                         max_lr=1e-1,\n",
        "                         steps_per_epoch=len(train_paths) // batch_size,\n",
        "                         lr_decay=0.8,\n",
        "                         cycle_length=5,\n",
        "                         mult_factor=1.5)\n",
        "\n",
        "lr_strategy=schedule if use_lr_strategy else None\n",
        "\n",
        "callbacks = get_callbacks(model_path, lr_strategy)\n",
        "\n",
        "with strategy.scope():\n",
        "  model = compile_model(strategy, architecture, img_size, n_classes)\n",
        "  history = model.fit(\n",
        "          dtrain,\n",
        "          validation_data=dvalid,\n",
        "          epochs=epochs, \n",
        "          verbose=1,\n",
        "          callbacks=callbacks,\n",
        "          steps_per_epoch=len(train_paths) // batch_size,\n",
        "          validation_steps=len(valid_paths) // batch_size)\n",
        "\n",
        "  # summarize history\n",
        "  plot_metric(history, 'loss', path)\n",
        "  plot_metric(history, 'auc', path)\n",
        "\n",
        "# To avoid timeout \n",
        "print(\"Avoiding timeout...\")\n",
        "while True:pass"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "211/211 [==============================] - 163s 532ms/step - loss: 0.3937 - auc: 0.7359 - val_loss: 0.3588 - val_auc: 0.8402\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.35878, saving model to output_path/single_model/Xception_model.h5\n",
            "Epoch 2/30\n",
            "211/211 [==============================] - 104s 495ms/step - loss: 0.2785 - auc: 0.8699 - val_loss: 0.2904 - val_auc: 0.8899\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.35878 to 0.29038, saving model to output_path/single_model/Xception_model.h5\n",
            "Epoch 3/30\n",
            "211/211 [==============================] - 105s 497ms/step - loss: 0.2513 - auc: 0.9009 - val_loss: 0.2578 - val_auc: 0.9072\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.29038 to 0.25776, saving model to output_path/single_model/Xception_model.h5\n",
            "Epoch 4/30\n",
            "211/211 [==============================] - 104s 495ms/step - loss: 0.2354 - auc: 0.9154 - val_loss: 0.2431 - val_auc: 0.9171\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.25776 to 0.24314, saving model to output_path/single_model/Xception_model.h5\n",
            "Epoch 5/30\n",
            "211/211 [==============================] - 105s 496ms/step - loss: 0.2246 - auc: 0.9259 - val_loss: 0.2473 - val_auc: 0.9255\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.24314\n",
            "Epoch 6/30\n",
            "211/211 [==============================] - 104s 492ms/step - loss: 0.2135 - auc: 0.9373 - val_loss: 0.2743 - val_auc: 0.9286\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.24314\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "Epoch 7/30\n",
            "211/211 [==============================] - 104s 494ms/step - loss: 0.1986 - auc: 0.9454 - val_loss: 0.2476 - val_auc: 0.9352\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.24314\n",
            "Epoch 8/30\n",
            "211/211 [==============================] - 105s 499ms/step - loss: 0.1870 - auc: 0.9504 - val_loss: 0.2288 - val_auc: 0.9363\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.24314 to 0.22881, saving model to output_path/single_model/Xception_model.h5\n",
            "Epoch 9/30\n",
            "211/211 [==============================] - 104s 492ms/step - loss: 0.1784 - auc: 0.9576 - val_loss: 0.2181 - val_auc: 0.9417\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.22881 to 0.21809, saving model to output_path/single_model/Xception_model.h5\n",
            "Epoch 10/30\n",
            "211/211 [==============================] - 104s 493ms/step - loss: 0.1696 - auc: 0.9643 - val_loss: 0.2285 - val_auc: 0.9393\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.21809\n",
            "Epoch 11/30\n",
            "211/211 [==============================] - 105s 497ms/step - loss: 0.1621 - auc: 0.9680 - val_loss: 0.2380 - val_auc: 0.9429\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.21809\n",
            "Epoch 12/30\n",
            "211/211 [==============================] - 105s 498ms/step - loss: 0.1521 - auc: 0.9709 - val_loss: 0.2444 - val_auc: 0.9431\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.21809\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "Epoch 13/30\n",
            "211/211 [==============================] - 106s 501ms/step - loss: 0.1442 - auc: 0.9745 - val_loss: 0.2455 - val_auc: 0.9440\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.21809\n",
            "Epoch 14/30\n",
            "211/211 [==============================] - 105s 497ms/step - loss: 0.1255 - auc: 0.9805 - val_loss: 0.2458 - val_auc: 0.9411\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.21809\n",
            "Epoch 00014: early stopping\n",
            "Avoiding timeout...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-a2192d4eb76a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# To avoid timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Avoiding timeout...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "xJj9CAJ_G-ru",
        "outputId": "8e499b6b-c08d-4b54-d6fe-37518faefb0f"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.download(model_path) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_05683be2-0631-44f1-b171-23eebdc2ace7\", \"Xception_model.h5\", 250928616)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqqEKrAvtfgc"
      },
      "source": [
        "#### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9oQpLJ8sZmN"
      },
      "source": [
        "with strategy.scope():\r\n",
        "    model = tf.keras.models.load_model(model_path)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfs3FFTjs6b9",
        "outputId": "29689a2d-14e7-45b7-e230-2b2eb87d3e56"
      },
      "source": [
        "test_decoder = build_decoder(with_labels=False, target_size=(img_size, img_size))\r\n",
        "\r\n",
        "df_sub = pd.read_csv(\"/content/sample_submission.csv\")\r\n",
        "test_paths = GCS_DS_PATH + \"/test/\" + df_sub['StudyInstanceUID'] + '.jpg'\r\n",
        "\r\n",
        "dtest = build_dataset(\r\n",
        "    test_paths, bsize=batch_size, repeat=False, \r\n",
        "    shuffle=False, augment=False, cache=False, \r\n",
        "    decode_fn=test_decoder\r\n",
        ")\r\n",
        "dtest"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: (None, 512, 512, 3), types: tf.float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25qF-JULtk3L",
        "outputId": "fdcf88d5-5f6a-4270-a9ab-4b3d25955822"
      },
      "source": [
        "y_preds = model.predict(dtest, verbose=1)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28/28 [==============================] - 133s 5s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "EXjJSTzjtpEs",
        "outputId": "a1672da9-7536-4929-9919-94c82fa78f61"
      },
      "source": [
        "df_sub.iloc[:, 1:] = y_preds\r\n",
        "display(df_sub)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StudyInstanceUID</th>\n",
              "      <th>ETT - Abnormal</th>\n",
              "      <th>ETT - Borderline</th>\n",
              "      <th>ETT - Normal</th>\n",
              "      <th>NGT - Abnormal</th>\n",
              "      <th>NGT - Borderline</th>\n",
              "      <th>NGT - Incompletely Imaged</th>\n",
              "      <th>NGT - Normal</th>\n",
              "      <th>CVC - Abnormal</th>\n",
              "      <th>CVC - Borderline</th>\n",
              "      <th>CVC - Normal</th>\n",
              "      <th>Swan Ganz Catheter Present</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.46923145579096002617...</td>\n",
              "      <td>0.119546</td>\n",
              "      <td>0.528664</td>\n",
              "      <td>0.393194</td>\n",
              "      <td>0.036304</td>\n",
              "      <td>0.031844</td>\n",
              "      <td>0.075014</td>\n",
              "      <td>0.645010</td>\n",
              "      <td>0.143100</td>\n",
              "      <td>0.380556</td>\n",
              "      <td>0.761918</td>\n",
              "      <td>0.910524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.84006870182611080091...</td>\n",
              "      <td>0.007573</td>\n",
              "      <td>0.005380</td>\n",
              "      <td>0.004553</td>\n",
              "      <td>0.005284</td>\n",
              "      <td>0.009292</td>\n",
              "      <td>0.001735</td>\n",
              "      <td>0.004315</td>\n",
              "      <td>0.185444</td>\n",
              "      <td>0.126697</td>\n",
              "      <td>0.810937</td>\n",
              "      <td>0.004496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.12219033294413119947...</td>\n",
              "      <td>0.003645</td>\n",
              "      <td>0.004357</td>\n",
              "      <td>0.011385</td>\n",
              "      <td>0.003205</td>\n",
              "      <td>0.005151</td>\n",
              "      <td>0.001784</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>0.172844</td>\n",
              "      <td>0.639076</td>\n",
              "      <td>0.406616</td>\n",
              "      <td>0.010347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.84994474380235968109...</td>\n",
              "      <td>0.084001</td>\n",
              "      <td>0.072812</td>\n",
              "      <td>0.118261</td>\n",
              "      <td>0.215506</td>\n",
              "      <td>0.201544</td>\n",
              "      <td>0.654710</td>\n",
              "      <td>0.245974</td>\n",
              "      <td>0.300276</td>\n",
              "      <td>0.506322</td>\n",
              "      <td>0.488120</td>\n",
              "      <td>0.167501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.35798987793805669662...</td>\n",
              "      <td>0.019663</td>\n",
              "      <td>0.021661</td>\n",
              "      <td>0.011341</td>\n",
              "      <td>0.007358</td>\n",
              "      <td>0.021364</td>\n",
              "      <td>0.002702</td>\n",
              "      <td>0.021598</td>\n",
              "      <td>0.123711</td>\n",
              "      <td>0.276223</td>\n",
              "      <td>0.749210</td>\n",
              "      <td>0.007860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3577</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.81464483108873296584...</td>\n",
              "      <td>0.046943</td>\n",
              "      <td>0.017608</td>\n",
              "      <td>0.018545</td>\n",
              "      <td>0.130108</td>\n",
              "      <td>0.157983</td>\n",
              "      <td>0.664904</td>\n",
              "      <td>0.264496</td>\n",
              "      <td>0.134427</td>\n",
              "      <td>0.253072</td>\n",
              "      <td>0.787060</td>\n",
              "      <td>0.039518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3578</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.33579133018211530710...</td>\n",
              "      <td>0.013494</td>\n",
              "      <td>0.015024</td>\n",
              "      <td>0.016397</td>\n",
              "      <td>0.006543</td>\n",
              "      <td>0.012295</td>\n",
              "      <td>0.001792</td>\n",
              "      <td>0.009367</td>\n",
              "      <td>0.396237</td>\n",
              "      <td>0.598116</td>\n",
              "      <td>0.353470</td>\n",
              "      <td>0.027119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3579</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.61472811086105902907...</td>\n",
              "      <td>0.005058</td>\n",
              "      <td>0.003086</td>\n",
              "      <td>0.003060</td>\n",
              "      <td>0.003450</td>\n",
              "      <td>0.008347</td>\n",
              "      <td>0.000234</td>\n",
              "      <td>0.003084</td>\n",
              "      <td>0.087685</td>\n",
              "      <td>0.215034</td>\n",
              "      <td>0.796372</td>\n",
              "      <td>0.002343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3580</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.19434375795525494655...</td>\n",
              "      <td>0.005023</td>\n",
              "      <td>0.004931</td>\n",
              "      <td>0.006234</td>\n",
              "      <td>0.001351</td>\n",
              "      <td>0.004495</td>\n",
              "      <td>0.000530</td>\n",
              "      <td>0.008498</td>\n",
              "      <td>0.217479</td>\n",
              "      <td>0.458706</td>\n",
              "      <td>0.453224</td>\n",
              "      <td>0.013548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3581</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.21182456828145534541...</td>\n",
              "      <td>0.005867</td>\n",
              "      <td>0.007521</td>\n",
              "      <td>0.010255</td>\n",
              "      <td>0.003479</td>\n",
              "      <td>0.004820</td>\n",
              "      <td>0.007275</td>\n",
              "      <td>0.003708</td>\n",
              "      <td>0.137878</td>\n",
              "      <td>0.191447</td>\n",
              "      <td>0.822769</td>\n",
              "      <td>0.007129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3582 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       StudyInstanceUID  ...  Swan Ganz Catheter Present\n",
              "0     1.2.826.0.1.3680043.8.498.46923145579096002617...  ...                    0.910524\n",
              "1     1.2.826.0.1.3680043.8.498.84006870182611080091...  ...                    0.004496\n",
              "2     1.2.826.0.1.3680043.8.498.12219033294413119947...  ...                    0.010347\n",
              "3     1.2.826.0.1.3680043.8.498.84994474380235968109...  ...                    0.167501\n",
              "4     1.2.826.0.1.3680043.8.498.35798987793805669662...  ...                    0.007860\n",
              "...                                                 ...  ...                         ...\n",
              "3577  1.2.826.0.1.3680043.8.498.81464483108873296584...  ...                    0.039518\n",
              "3578  1.2.826.0.1.3680043.8.498.33579133018211530710...  ...                    0.027119\n",
              "3579  1.2.826.0.1.3680043.8.498.61472811086105902907...  ...                    0.002343\n",
              "3580  1.2.826.0.1.3680043.8.498.19434375795525494655...  ...                    0.013548\n",
              "3581  1.2.826.0.1.3680043.8.498.21182456828145534541...  ...                    0.007129\n",
              "\n",
              "[3582 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vkbTSFztsBM"
      },
      "source": [
        "df_sub.to_csv('submission.csv',index=False)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C68h06shyB5z"
      },
      "source": [
        "#### TTA\r\n",
        "A final technique that can raise accuracy by one percent or two is test time augmentation (TTA). This involves taking a series of different versions of the original image (for example cropping different areas, or changing the zoom) and passing them through the model. The average output is then calculated for the different versions and this is given as the final output score for the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6hNj7FOyqvx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "76f0d808-f55a-47f3-d982-169a1ff2f22f"
      },
      "source": [
        "# Test time augmentation rounds\r\n",
        "TTA = 5\r\n",
        "NUM_TESTING_IMAGES = df_sub.shape[0]\r\n",
        "steps = TTA * ((NUM_TESTING_IMAGES / batch_size) + 1)\r\n",
        "\r\n",
        "# Get the test dataset with tta to extract image\r\n",
        "tta_dtest = build_tta(test_paths,\r\n",
        "                      decode_fn=build_decoder(with_labels=False, \r\n",
        "                                              target_size=(img_size, img_size)),\r\n",
        "                      augment_fn=build_augmenter(with_labels=False), \r\n",
        "                      bsize=batch_size, \r\n",
        "                      tta = True)\r\n",
        "\r\n",
        "probabilities = model.predict(tta_dtest, steps = steps, verbose=1)[: TTA * NUM_TESTING_IMAGES]\r\n",
        "probabilities = np.mean(probabilities.reshape((NUM_TESTING_IMAGES, TTA, n_classes), order = 'F'), axis = 1)\r\n",
        "\r\n",
        "df_sub.iloc[:, 1:] = probabilities\r\n",
        "display(df_sub)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "144/144 [==============================] - 428s 3s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StudyInstanceUID</th>\n",
              "      <th>ETT - Abnormal</th>\n",
              "      <th>ETT - Borderline</th>\n",
              "      <th>ETT - Normal</th>\n",
              "      <th>NGT - Abnormal</th>\n",
              "      <th>NGT - Borderline</th>\n",
              "      <th>NGT - Incompletely Imaged</th>\n",
              "      <th>NGT - Normal</th>\n",
              "      <th>CVC - Abnormal</th>\n",
              "      <th>CVC - Borderline</th>\n",
              "      <th>CVC - Normal</th>\n",
              "      <th>Swan Ganz Catheter Present</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.46923145579096002617...</td>\n",
              "      <td>0.086221</td>\n",
              "      <td>0.473355</td>\n",
              "      <td>0.410325</td>\n",
              "      <td>0.016394</td>\n",
              "      <td>0.020533</td>\n",
              "      <td>0.060645</td>\n",
              "      <td>0.898600</td>\n",
              "      <td>0.108563</td>\n",
              "      <td>0.391079</td>\n",
              "      <td>0.775466</td>\n",
              "      <td>0.945510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.84006870182611080091...</td>\n",
              "      <td>0.006655</td>\n",
              "      <td>0.005371</td>\n",
              "      <td>0.004882</td>\n",
              "      <td>0.006336</td>\n",
              "      <td>0.009191</td>\n",
              "      <td>0.002458</td>\n",
              "      <td>0.005262</td>\n",
              "      <td>0.220803</td>\n",
              "      <td>0.099987</td>\n",
              "      <td>0.820276</td>\n",
              "      <td>0.004052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.12219033294413119947...</td>\n",
              "      <td>0.003918</td>\n",
              "      <td>0.006102</td>\n",
              "      <td>0.017008</td>\n",
              "      <td>0.006133</td>\n",
              "      <td>0.007252</td>\n",
              "      <td>0.005150</td>\n",
              "      <td>0.006797</td>\n",
              "      <td>0.127584</td>\n",
              "      <td>0.584959</td>\n",
              "      <td>0.463695</td>\n",
              "      <td>0.006493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.84994474380235968109...</td>\n",
              "      <td>0.098540</td>\n",
              "      <td>0.106698</td>\n",
              "      <td>0.169530</td>\n",
              "      <td>0.182062</td>\n",
              "      <td>0.155598</td>\n",
              "      <td>0.685881</td>\n",
              "      <td>0.250795</td>\n",
              "      <td>0.291958</td>\n",
              "      <td>0.374130</td>\n",
              "      <td>0.656114</td>\n",
              "      <td>0.221868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.35798987793805669662...</td>\n",
              "      <td>0.017340</td>\n",
              "      <td>0.023198</td>\n",
              "      <td>0.015782</td>\n",
              "      <td>0.006163</td>\n",
              "      <td>0.016178</td>\n",
              "      <td>0.004137</td>\n",
              "      <td>0.039442</td>\n",
              "      <td>0.112227</td>\n",
              "      <td>0.314522</td>\n",
              "      <td>0.706985</td>\n",
              "      <td>0.007338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3577</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.81464483108873296584...</td>\n",
              "      <td>0.044929</td>\n",
              "      <td>0.020648</td>\n",
              "      <td>0.025402</td>\n",
              "      <td>0.137272</td>\n",
              "      <td>0.159822</td>\n",
              "      <td>0.669503</td>\n",
              "      <td>0.287963</td>\n",
              "      <td>0.139817</td>\n",
              "      <td>0.285589</td>\n",
              "      <td>0.809757</td>\n",
              "      <td>0.032516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3578</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.33579133018211530710...</td>\n",
              "      <td>0.010752</td>\n",
              "      <td>0.014907</td>\n",
              "      <td>0.020727</td>\n",
              "      <td>0.007455</td>\n",
              "      <td>0.011824</td>\n",
              "      <td>0.002623</td>\n",
              "      <td>0.010559</td>\n",
              "      <td>0.298381</td>\n",
              "      <td>0.658231</td>\n",
              "      <td>0.362242</td>\n",
              "      <td>0.017353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3579</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.61472811086105902907...</td>\n",
              "      <td>0.005007</td>\n",
              "      <td>0.004110</td>\n",
              "      <td>0.005313</td>\n",
              "      <td>0.003211</td>\n",
              "      <td>0.008150</td>\n",
              "      <td>0.000538</td>\n",
              "      <td>0.005007</td>\n",
              "      <td>0.068682</td>\n",
              "      <td>0.280652</td>\n",
              "      <td>0.741383</td>\n",
              "      <td>0.002638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3580</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.19434375795525494655...</td>\n",
              "      <td>0.005486</td>\n",
              "      <td>0.008757</td>\n",
              "      <td>0.011070</td>\n",
              "      <td>0.001542</td>\n",
              "      <td>0.004921</td>\n",
              "      <td>0.000858</td>\n",
              "      <td>0.016855</td>\n",
              "      <td>0.172121</td>\n",
              "      <td>0.526073</td>\n",
              "      <td>0.407416</td>\n",
              "      <td>0.009962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3581</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.21182456828145534541...</td>\n",
              "      <td>0.006264</td>\n",
              "      <td>0.010351</td>\n",
              "      <td>0.019258</td>\n",
              "      <td>0.006431</td>\n",
              "      <td>0.006114</td>\n",
              "      <td>0.012213</td>\n",
              "      <td>0.006619</td>\n",
              "      <td>0.125489</td>\n",
              "      <td>0.165539</td>\n",
              "      <td>0.842713</td>\n",
              "      <td>0.006457</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3582 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       StudyInstanceUID  ...  Swan Ganz Catheter Present\n",
              "0     1.2.826.0.1.3680043.8.498.46923145579096002617...  ...                    0.945510\n",
              "1     1.2.826.0.1.3680043.8.498.84006870182611080091...  ...                    0.004052\n",
              "2     1.2.826.0.1.3680043.8.498.12219033294413119947...  ...                    0.006493\n",
              "3     1.2.826.0.1.3680043.8.498.84994474380235968109...  ...                    0.221868\n",
              "4     1.2.826.0.1.3680043.8.498.35798987793805669662...  ...                    0.007338\n",
              "...                                                 ...  ...                         ...\n",
              "3577  1.2.826.0.1.3680043.8.498.81464483108873296584...  ...                    0.032516\n",
              "3578  1.2.826.0.1.3680043.8.498.33579133018211530710...  ...                    0.017353\n",
              "3579  1.2.826.0.1.3680043.8.498.61472811086105902907...  ...                    0.002638\n",
              "3580  1.2.826.0.1.3680043.8.498.19434375795525494655...  ...                    0.009962\n",
              "3581  1.2.826.0.1.3680043.8.498.21182456828145534541...  ...                    0.006457\n",
              "\n",
              "[3582 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1caPfOOFn5r"
      },
      "source": [
        "df_sub.to_csv('submission_tta.csv',index=False)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-ye4Hxtx3fE"
      },
      "source": [
        "### Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xkrs_gE-Du6M",
        "outputId": "533efc27-2485-4a3f-b533-e207ca0e6bb8"
      },
      "source": [
        "image_paths = paths[0:train_limit]\r\n",
        "image_labels = labels[0:train_limit]\r\n",
        "\r\n",
        "kf = IterativeStratification(n_splits=n_fold, order=1)\r\n",
        "\r\n",
        "for fold in range(0, n_fold):\r\n",
        "\r\n",
        "    print(f\"\\nFold: {fold}\")\r\n",
        "\r\n",
        "    path = os.path.join(\"output_path\", str(fold))\r\n",
        "    mkdir_if_not_exist(path)\r\n",
        "\r\n",
        "    model_path = os.path.join(path, \"model_\"+str(fold)+\".h5\")\r\n",
        "\r\n",
        "    result = next(kf.split(X=image_paths, y=image_labels), None)\r\n",
        "\r\n",
        "    train = image_paths[result[0]].tolist()\r\n",
        "    train_labels = [id_label_map[k] for k in train]\r\n",
        "    val = image_paths[result[1]].tolist()\r\n",
        "    valid_labels = [id_label_map[k] for k in val]\r\n",
        "\r\n",
        "    print(f\"train shape: {len(train)}\")\r\n",
        "    print(f\"train steps_per_epoch: {len(train) // batch_size}\")\r\n",
        "    print(f\"val shape: {len(val)}\")\r\n",
        "    print(f\"validation steps_per_epoch: {len(val) // batch_size}\")\r\n",
        "\r\n",
        "    # Build the tensorflow datasets\r\n",
        "    dtrain = build_dataset(\r\n",
        "        train, train_labels, bsize=batch_size, decode_fn=decoder\r\n",
        "    )\r\n",
        "\r\n",
        "    dvalid = build_dataset(\r\n",
        "        val, valid_labels, bsize=batch_size, \r\n",
        "        repeat=False, shuffle=False, augment=False, decode_fn=decoder\r\n",
        "    )\r\n",
        "\r\n",
        "    tf.keras.backend.clear_session()\r\n",
        "\r\n",
        "    schedule = SGDRScheduler(min_lr=1e-3,\r\n",
        "                         max_lr=1e-1,\r\n",
        "                         steps_per_epoch=np.ceil(len(train)/batch_size),\r\n",
        "                         lr_decay=0.8,\r\n",
        "                         cycle_length=5,\r\n",
        "                         mult_factor=1.5)\r\n",
        "\r\n",
        "    lr_strategy=schedule if use_lr_strategy else None\r\n",
        "\r\n",
        "\r\n",
        "    callbacks = get_callbacks(model_path, lr_strategy)\r\n",
        "\r\n",
        "    with strategy.scope():\r\n",
        "      model = compile_model(strategy, architecture, img_size, n_classes)\r\n",
        "      \r\n",
        "      ###########\r\n",
        "      # Training\r\n",
        "      ###########\r\n",
        "\r\n",
        "      history = model.fit(\r\n",
        "          dtrain,\r\n",
        "          validation_data=dvalid,\r\n",
        "          epochs=epochs, verbose=1,\r\n",
        "          callbacks=callbacks,\r\n",
        "          steps_per_epoch=len(train) // batch_size,\r\n",
        "          validation_steps=len(val) // batch_size)\r\n",
        "\r\n",
        "      # summarize history\r\n",
        "      plot_metric(history, 'loss', path)\r\n",
        "      plot_metric(history, 'auc', path)\r\n",
        "      \r\n",
        "      # in order to release the memory\r\n",
        "      del history\r\n",
        "      del model\r\n",
        "      gc.collect()\r\n",
        "\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "for fold in range(0, n_fold):\r\n",
        "  print(f\"downloading model_{fold}...\")\r\n",
        "  path = os.path.join(\"output_path\", str(fold))\r\n",
        "  mkdir_if_not_exist(path)\r\n",
        "  model_path = os.path.join(path, \"model_\"+str(fold)+\".h5\")\r\n",
        "  files.download(model_path) \r\n",
        "\r\n",
        "# To avoid timeout \r\n",
        "print(\"Avoiding timeout...\")\r\n",
        "while True:pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold: 0\n",
            "train shape: 24065\n",
            "train steps_per_epoch: 188\n",
            "val shape: 6018\n",
            "validation steps_per_epoch: 47\n",
            "Epoch 1/30\n",
            " 54/188 [=======>......................] - ETA: 5:34 - loss: 0.4508 - auc: 0.6829"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O6Frym0Y7ad"
      },
      "source": [
        "#### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "C9NmGUoVBvav",
        "outputId": "6604bbbd-f513-40e3-c6a4-3fe5e5903855"
      },
      "source": [
        "test_paths = GCS_DS_PATH + \"test/\" + df_sub['StudyInstanceUID'] + '.jpg'\r\n",
        "test_paths[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'gs://kds-8fdde4eb643ffca87f4d2e302b48cea859367cad0b9a6e98d65c407atest/1.2.826.0.1.3680043.8.498.46923145579096002617106567297135160932.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "spYtDp-mW_7C",
        "outputId": "241ab57e-983d-47ff-957c-7e05674ced07"
      },
      "source": [
        "test_decoder = build_decoder(with_labels=False, target_size=(img_size, img_size))\r\n",
        "\r\n",
        "dtest = build_dataset(\r\n",
        "    test_paths[0:test_limit], bsize=batch_size, repeat=False, \r\n",
        "    shuffle=False, augment=False, cache=False, \r\n",
        "    decode_fn=test_decoder\r\n",
        ")\r\n",
        "\r\n",
        "ensemble_preds = np.zeros((len(test_paths[0:test_limit]), n_classes), dtype=np.float)\r\n",
        "\r\n",
        "for fold in range(0, n_fold):\r\n",
        "  print(f\"model: {fold}\")\r\n",
        "  path = os.path.join(\"output_path\", str(fold))\r\n",
        "  mkdir_if_not_exist(path)\r\n",
        "  model_path = os.path.join(path, \"model_\"+str(fold)+\".h5\")\r\n",
        "  \r\n",
        "  with strategy.scope():\r\n",
        "      model = tf.keras.models.load_model(model_path)\r\n",
        "\r\n",
        "      y_preds = model.predict(dtest, verbose=1)\r\n",
        "\r\n",
        "      # sum the predicted values\r\n",
        "      ensemble_preds += np.array(y_preds, dtype=np.float)\r\n",
        "\r\n",
        "# average the predicted values\r\n",
        "ensemble_preds /= n_fold\r\n",
        "df_sub.iloc[:, 1:] = ensemble_preds\r\n",
        "display(df_sub)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model: 0\n",
            "56/56 [==============================] - 82s 1s/step\n",
            "model: 1\n",
            "56/56 [==============================] - 81s 1s/step\n",
            "model: 2\n",
            "56/56 [==============================] - 83s 1s/step\n",
            "model: 3\n",
            "56/56 [==============================] - 84s 1s/step\n",
            "model: 4\n",
            "56/56 [==============================] - 84s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StudyInstanceUID</th>\n",
              "      <th>ETT - Abnormal</th>\n",
              "      <th>ETT - Borderline</th>\n",
              "      <th>ETT - Normal</th>\n",
              "      <th>NGT - Abnormal</th>\n",
              "      <th>NGT - Borderline</th>\n",
              "      <th>NGT - Incompletely Imaged</th>\n",
              "      <th>NGT - Normal</th>\n",
              "      <th>CVC - Abnormal</th>\n",
              "      <th>CVC - Borderline</th>\n",
              "      <th>CVC - Normal</th>\n",
              "      <th>Swan Ganz Catheter Present</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.46923145579096002617...</td>\n",
              "      <td>0.003980</td>\n",
              "      <td>0.148109</td>\n",
              "      <td>0.751670</td>\n",
              "      <td>0.006566</td>\n",
              "      <td>0.004812</td>\n",
              "      <td>0.017220</td>\n",
              "      <td>0.967534</td>\n",
              "      <td>0.034764</td>\n",
              "      <td>0.143648</td>\n",
              "      <td>0.961513</td>\n",
              "      <td>0.997017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.84006870182611080091...</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>0.000179</td>\n",
              "      <td>0.000255</td>\n",
              "      <td>0.000251</td>\n",
              "      <td>0.006026</td>\n",
              "      <td>0.005555</td>\n",
              "      <td>0.994002</td>\n",
              "      <td>0.000118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.12219033294413119947...</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>0.000368</td>\n",
              "      <td>0.000274</td>\n",
              "      <td>0.000316</td>\n",
              "      <td>0.000569</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.000327</td>\n",
              "      <td>0.028151</td>\n",
              "      <td>0.392895</td>\n",
              "      <td>0.643898</td>\n",
              "      <td>0.000217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.84994474380235968109...</td>\n",
              "      <td>0.003846</td>\n",
              "      <td>0.029073</td>\n",
              "      <td>0.049871</td>\n",
              "      <td>0.018470</td>\n",
              "      <td>0.013193</td>\n",
              "      <td>0.957945</td>\n",
              "      <td>0.039246</td>\n",
              "      <td>0.113185</td>\n",
              "      <td>0.254475</td>\n",
              "      <td>0.611831</td>\n",
              "      <td>0.019305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.35798987793805669662...</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>0.000643</td>\n",
              "      <td>0.000559</td>\n",
              "      <td>0.000777</td>\n",
              "      <td>0.000815</td>\n",
              "      <td>0.000597</td>\n",
              "      <td>0.002610</td>\n",
              "      <td>0.050831</td>\n",
              "      <td>0.237322</td>\n",
              "      <td>0.804757</td>\n",
              "      <td>0.000424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3577</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.81464483108873296584...</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>0.001749</td>\n",
              "      <td>0.004719</td>\n",
              "      <td>0.008885</td>\n",
              "      <td>0.017725</td>\n",
              "      <td>0.926567</td>\n",
              "      <td>0.029308</td>\n",
              "      <td>0.006811</td>\n",
              "      <td>0.090162</td>\n",
              "      <td>0.958868</td>\n",
              "      <td>0.001191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3578</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.33579133018211530710...</td>\n",
              "      <td>0.000666</td>\n",
              "      <td>0.001067</td>\n",
              "      <td>0.002221</td>\n",
              "      <td>0.001579</td>\n",
              "      <td>0.003761</td>\n",
              "      <td>0.000356</td>\n",
              "      <td>0.002721</td>\n",
              "      <td>0.590587</td>\n",
              "      <td>0.351006</td>\n",
              "      <td>0.168774</td>\n",
              "      <td>0.001190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3579</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.61472811086105902907...</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>0.000290</td>\n",
              "      <td>0.000317</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>0.000221</td>\n",
              "      <td>0.006323</td>\n",
              "      <td>0.024265</td>\n",
              "      <td>0.967607</td>\n",
              "      <td>0.000125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3580</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.19434375795525494655...</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>0.000629</td>\n",
              "      <td>0.000274</td>\n",
              "      <td>0.000299</td>\n",
              "      <td>0.000372</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.000618</td>\n",
              "      <td>0.062418</td>\n",
              "      <td>0.274576</td>\n",
              "      <td>0.631775</td>\n",
              "      <td>0.000148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3581</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.21182456828145534541...</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>0.000188</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>0.000246</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>0.010997</td>\n",
              "      <td>0.016590</td>\n",
              "      <td>0.986736</td>\n",
              "      <td>0.000191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3582 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       StudyInstanceUID  ...  Swan Ganz Catheter Present\n",
              "0     1.2.826.0.1.3680043.8.498.46923145579096002617...  ...                    0.997017\n",
              "1     1.2.826.0.1.3680043.8.498.84006870182611080091...  ...                    0.000118\n",
              "2     1.2.826.0.1.3680043.8.498.12219033294413119947...  ...                    0.000217\n",
              "3     1.2.826.0.1.3680043.8.498.84994474380235968109...  ...                    0.019305\n",
              "4     1.2.826.0.1.3680043.8.498.35798987793805669662...  ...                    0.000424\n",
              "...                                                 ...  ...                         ...\n",
              "3577  1.2.826.0.1.3680043.8.498.81464483108873296584...  ...                    0.001191\n",
              "3578  1.2.826.0.1.3680043.8.498.33579133018211530710...  ...                    0.001190\n",
              "3579  1.2.826.0.1.3680043.8.498.61472811086105902907...  ...                    0.000125\n",
              "3580  1.2.826.0.1.3680043.8.498.19434375795525494655...  ...                    0.000148\n",
              "3581  1.2.826.0.1.3680043.8.498.21182456828145534541...  ...                    0.000191\n",
              "\n",
              "[3582 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au14_jpipx9e"
      },
      "source": [
        "# References\n",
        "\n",
        "\n",
        "1.   [RANZCR CLiP - Catheter and Line Position Challenge](https://www.kaggle.com/c/ranzcr-clip-catheter-line-classification)\n",
        "2.   [CoroNet: A deep neural network for detection and diagnosis of COVID-19 from chest x-ray images](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7274128/)\n",
        "3.   [RANZCR TF RECORDS 768 STRATIFIED](https://www.kaggle.com/ragnar123/ranzcr-tf-records-768-stratified/code)\n",
        "\n",
        "\n"
      ]
    }
  ]
}